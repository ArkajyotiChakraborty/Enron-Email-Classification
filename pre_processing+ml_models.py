# -*- coding: utf-8 -*-
"""Pre-Processing+ML_Models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lAX-rwPIYOjmH4mNtRWG0WCtT4P0tQJq

Converting the datasets into CSV format.
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import email
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns; sns.set_style('whitegrid')
from nltk.tokenize.regexp import RegexpTokenizer

all_file_name, all_text, all_label = [], [], []
for i in range(1, 9):
  for f in os.listdir(f"/content/drive/MyDrive/enron_with_categories/{i}"):
    if f.endswith('.txt'): continue
    with open(f"/content/drive/MyDrive/enron_with_categories/{i}/{f}", 'r') as in_file:
      cat = in_file.read()
    cat_by_line = cat.split('\n')
    for j in range(len(cat_by_line)):
      cat_by_comma = cat_by_line[j].split(',')
      if cat_by_comma[0] == "1":
        label = '.'.join([cat_by_comma[0], cat_by_comma[1]])
        with open(f"/content/drive/MyDrive/enron_with_categories/{i}/{f.replace('.cats', '.txt')}", 'r') as in_file:
              text = in_file.read()
        file_name = f"{i}/{f.replace('.cats', '')}"
        all_file_name.append(file_name)
        all_text.append(text)
        all_label.append(label)

data = pd.DataFrame(
    {"file_name": all_file_name,
    "text": all_text,
    "label": all_label}
)

data.to_csv("processed_data-1.csv", index=False)

df = pd.read_csv('/content/drive/MyDrive/enron_with_categories/processed_data-1.csv')
df

df = df[df['label']!=1.7]
df = df[df['label']!=1.8]

def get_text(msg):
    #To get the content from email
    parts = []
    for part in msg.walk():
        if part.get_content_type() == 'text/plain':
            parts.append( part.get_payload() )
    return ''.join(parts)

def split_email_addresses(line):
    #To separate multiple email addresses
    if line:
        address = line.split(',')
        address = frozenset(map(lambda x: x.strip(), address))
    else:
        address = None
    return address

def preprocess_folder(data):
    folders = []
    for item in data:
        if item == None or item == '':
            folders.append(np.nan)
        else:
            item = item.split("\\")[-1]
            item = item.lower()
            folders.append(item)
    print("Folder cleaned!")
    return folders

messages = list(map(email.message_from_string, df['text']))
df.drop('text', axis=1, inplace=True)
# Getting fields from parsed email objects
keys = messages[0].keys()
for key in keys:
    df[key] = [doc[key] for doc in messages]
# Parsing the content from emails
df['content'] = list(map(get_text, messages))
# Splitting multiple email addresses
df['From'] = df['From'].map(split_email_addresses)
df['To'] = df['To'].map(split_email_addresses)

df =df[['label', 'content']]
df

def extract_subject_part(text):
  subject_index = text.rfind("Subject:")
  if subject_index != -1:
    return text[subject_index:]
  else:
    return text

df['clean_content'] = df['content'].apply(extract_subject_part)
df

def clean_str(string, reg = RegexpTokenizer(r'[a-z]+')
    string = string.lower()
    tokens = reg.tokenize(string)
    return " ".join(tokens)
df.head()

df['clean_content'] = df['clean_content'].apply(lambda string: clean_str(string))
df.head()

df.to_csv('clean_csv_2.csv')

df = pd.read_csv('/content/drive/MyDrive/enron_with_categories/clean_csv_2.csv')
df

df = df.dropna(axis = 0)
df

label_map = {1.1: 0, 1.2: 1, 1.3: 2, 1.4: 3, 1.5: 4, 1.6: 5}
df['label_value'] = df['label'].map(label_map)
df

df = df.sample(frac = 1, random_state = 42)
df

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report
from sklearn import svm
import sklearn.model_selection as model_selection

X_train, X_test, y_train, y_test = train_test_split(df['clean_content'], df['label_value'], test_size=0.2, random_state=42)

tfidf_vectorizer = TfidfVectorizer(max_features=3000, stop_words='english')
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

model = MultinomialNB()
model.fit(X_train_tfidf, y_train)
y_pred = model.predict(X_test_tfidf)
print(classification_report(y_test, y_pred))

rbf = svm.SVC(kernel='rbf', gamma=0.5, C=0.1).fit(X_train_tfidf, y_train)
poly = svm.SVC(kernel='poly', degree=3, C=1).fit(X_train_tfidf, y_train)
poly_pred = poly.predict(X_test_tfidf)
rbf_pred = rbf.predict(X_test_tfidf)
print("Polynomial Kernel Report")
print(classification_report(y_test, poly_pred))
print("RBF Kernel Report")
print(classification_report(y_test, rbf_pred))